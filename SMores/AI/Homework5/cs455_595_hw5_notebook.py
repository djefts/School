# -*- coding: utf-8 -*-
"""cs455-595-hw4-notebook

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Z9LPj0mVq1Z5FJN3YYtX09U89zVIWpp6
"""

# Required Modules
import tensorflow as tf
import numpy as np
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
# %matplotlib inline

from sklearn import datasets
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score
from sklearn.metrics import precision_recall_curve, average_precision_score, roc_curve, auc

from sklearn.utils.fixes import signature

############################################################
# Data Preparation

# Load Data Set
# Available from: https://www.openml.org/d/53
# Sklearn has a fetch capability
from sklearn.datasets import fetch_openml

heart = fetch_openml(name = 'heart-statlog', version = 1)

data = heart.data
target = (heart.target == 'present').astype(float)

# Scale Data Set
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data)

# Splits (80% training, 20% Testing)
X_train, X_test, y_train, y_test = train_test_split(data_scaled,
                                                    target,
                                                    test_size = 0.33)

# Reshape Training to be a column vector
y_train = y_train.reshape(-1, 1)
y_test = y_test.reshape(-1, 1)

############################################################
# Constructon 
#
# Defines a Keras sequential model with the following configuration:
#  Input  13
#  Hidden 5 (relu) 
#  Output 1  (sigmoid) - probability of heart disease
#
# The model will be optimized using gradient descent with the mean
# square error as loss

tf.reset_default_graph()

model = tf.keras.Sequential()
model.add(tf.keras.layers.Dense(5, activation = 'relu', input_shape = (13,)))
model.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))

model.compile(optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01),
              loss = 'mse')

#############################################################
# Training
#
with tf.Session() as sess:
    # Initialize Model
    init = tf.global_variables_initializer()
    init.run()
    
    # Callback to save graph to Tensorboard
    tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir = './hw-logs',
                                                    write_graph = True)
    
    # Callback to save the model's checkpoint (weights only)
    saver_cb = tf.keras.callbacks.ModelCheckpoint('./hw-checkpoint.chkp',
                                                  save_weights_only = True,
                                                  verbose = 1)
    # Train the model
    metrics = model.fit(X_train, y_train,
                        epochs = 1000,
                        batch_size = 20,
                        validation_data = (X_test, y_test),
                        callbacks = [saver_cb, tensorboard_cb])

############################################################
# Prediction
#
# The model will give a probability.  We must then use a 
# threshold to determine if 0 - No Heart Disease or 
# 1 - Heart Disease

with tf.Session() as sess:
    model.load_weights('./hw-checkpoint.chkp')
    y_prob = model.predict(X_test)
    y_pred = (y_prob >= 0.5)

############################################################  
# Evaluate results
#
#  Using y_prob, y_pred, and y_test and the sklearn metrics module
#  to calculate and print and/or plot the following:

# Confusion Matrix
print("\n\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# Accuracy
print("Accuracy Score =", str(accuracy_score(y_test, y_pred)))

# Precision
print("Precision Score =", str(precision_score(y_test, y_pred)))

# Recall
print("Recall Score =", str(recall_score(y_test, y_pred)))

# Precision-Recall Curve
precision, recall, thresholds = precision_recall_curve(y_test, y_pred)
average_precision = average_precision_score(y_test, y_prob)
step_kwargs = ({'step': 'post'}
               if 'step' in signature(plt.fill_between).parameters
               else {})
plt.step(recall, precision, color = 'g', alpha = 0.2, where = 'post')
plt.fill_between(recall, precision, alpha = 0.2, color = 'g', **step_kwargs)
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall curve: AP={0:0.2f}'.format(average_precision))
plt.show()

# ROC Curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred)
roc_auc = auc(fpr, tpr)
plt.figure()
lw = 2
plt.plot(fpr, tpr, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
# plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc="lower right")
plt.show()

# Area under ROC Curve
print('Area under the ROC Curve={0:0.2f}'.format(roc_auc))
